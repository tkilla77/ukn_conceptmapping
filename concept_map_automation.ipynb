{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Map Analysis\n",
    "Analyse a set of dynamic graphs, computing for the change in [https://en.wikipedia.org/wiki/Betweenness_centrality](betweenness) centrality pre- / post-intervention.\n",
    "\n",
    "The intervention is an interdisciplinary lesson, and students are asked to create a concept map at the beginning and at the end of the lesson. Concept maps are created from a set of given concepts. Mapping is performed in [https://www.ddi.uni-konstanz.de/forschung/forschungsprojekte/concept-map-creator/](Concept Map Creator).\n",
    "\n",
    "The resulting concept maps can be downloaded from _Concept Map Creator_ as zip-file per class. Each zip-file contains a hierarchical structure, with a folder per student, and all the student's graphs contained therein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (3.3)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install networkx tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "  * read zip file\n",
    "  * find student's with at least two graphs\n",
    "  * pick the oldest and most recent graph\n",
    "  * analyse each graph for per-concept node centrality\n",
    "  * return a dictionary of {concept : change}\n",
    "\n",
    "## Massage Graphs\n",
    "The produced graphs cannot be read by networkx nor graph_tool as they do not conform to the graphml spec. \n",
    "\n",
    "Let's massage them a little:\n",
    "   * fix graphml namespace definitions: \n",
    "     * replace `xmlns=\"http://graphml.graphdrawing.org/xmlns/graphml\"` by `xmlns=\"http://graphml.graphdrawing.org/xmlns\"`.\n",
    "     * replace `xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns/graphml` by `xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns`\n",
    "   * fix graphml attribute definitions:\n",
    "     * add `attr.type=\"string\"` to the keys for with id `d2`, `d7`, and `d8`.\n",
    "     * remove the illegal `d13` key with `<key for=\"graphml\"`\n",
    "   * change graph from directed to undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_graphml(xmlcontents):\n",
    "    xmlcontents = xmlcontents.replace(\"http://graphml.graphdrawing.org/xmlns/graphml\", \"http://graphml.graphdrawing.org/xmlns\")\n",
    "    xmlcontents = xmlcontents.replace('<key for=\"graphml\" id=\"d13\" yfiles.type=\"resources\"/>\\n', '')\n",
    "    xmlcontents = xmlcontents.replace('edgedefault=\"directed\"', 'edgedefault=\"undirected\"')\n",
    "    xmlcontents = xmlcontents.replace('<key for=\"node\" id=\"d2\"', '<key for=\"node\" id=\"d2\" attr.type=\"string\"')\n",
    "    xmlcontents = xmlcontents.replace('<key for=\"edge\" id=\"d7\"', '<key for=\"edge\" id=\"d7\" attr.type=\"string\"')\n",
    "    xmlcontents = xmlcontents.replace('<key for=\"graph\" id=\"d8\"', '<key for=\"graph\" id=\"d8\" attr.type=\"string\"')\n",
    "    return xmlcontents\n",
    "\n",
    "def read_student_graph(zip_file, folder_info):\n",
    "    from io import TextIOWrapper\n",
    "    import pathlib\n",
    "    import graph_tool as gt\n",
    "    import os\n",
    "    result = {}\n",
    "    for fileinfo in zip_file.infolist():\n",
    "        if not fileinfo.is_dir() and fileinfo.filename.startswith(folder_info.filename):\n",
    "            print(f'Extracting {fileinfo.filename}')\n",
    "            path = pathlib.Path('tmp/'+fileinfo.filename)\n",
    "            with zip_file.open(fileinfo) as graph_file:\n",
    "                contents = TextIOWrapper(graph_file, \"UTF-8\").read()\n",
    "                fixed = fix_graphml(contents)\n",
    "\n",
    "                os.makedirs(path.parent, exist_ok=True)\n",
    "                with TextIOWrapper(open(path, \"wb\"), \"UTF-8\") as out:\n",
    "                    out.write(fixed)\n",
    "            graph = gt.load_graph(str(path.absolute()))\n",
    "            prop = graph.new_vertex_property(\"double\")\n",
    "            vc, ec = gt.centrality.betweenness(graph, prop)\n",
    "            #gt.draw.graph_draw(graph)\n",
    "            centrality_dict = dict(zip(graph.vertex_properties['id'], vc))\n",
    "            result[path.stem] = centrality_dict  # only use vertex centrality\n",
    "    if (len(result) > 1):\n",
    "        return result\n",
    "    print(f'Ignoring {folder_info.filename} as we need at least two graphs')\n",
    "\n",
    "def read_recording(filename):\n",
    "    \"\"\"Read the given filename and produce a dictionary from geonameid to a dict per entity.\"\"\"\n",
    "    import zipfile\n",
    "    from tqdm.auto import tqdm\n",
    "    result = {}\n",
    "    with zipfile.ZipFile(filename) as recording:\n",
    "        for fileinfo in recording.infolist():\n",
    "            if fileinfo.is_dir():\n",
    "                result[fileinfo.filename] = read_student_graph(recording, fileinfo)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting libisseg@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Ignoring libisseg@ksr.ch/ as we need at least two graphs\n",
      "Extracting seanbuck@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Ignoring seanbuck@ksr.ch/ as we need at least two graphs\n",
      "Extracting iawegner@ksr.ch/2024-09-02 07:52:25.graphml\n",
      "Extracting iawegner@ksr.ch/2024-09-02 09:16:15.graphml\n",
      "Extracting lyaepper@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting lyaepper@ksr.ch/2024-09-02 09:16:14.graphml\n",
      "Extracting tomfuchs@ksr.ch/2024-09-02 09:16:14.graphml\n",
      "Ignoring tomfuchs@ksr.ch/ as we need at least two graphs\n",
      "Extracting legoetsc@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Ignoring legoetsc@ksr.ch/ as we need at least two graphs\n",
      "Extracting noahelms@ksr.ch/2024-09-02 07:52:25.graphml\n",
      "Ignoring noahelms@ksr.ch/ as we need at least two graphs\n",
      "Extracting estlopez@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting estlopez@ksr.ch/2024-09-02 09:16:15.graphml\n",
      "Extracting maxoeler@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Ignoring maxoeler@ksr.ch/ as we need at least two graphs\n",
      "Extracting niokrasc@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting niokrasc@ksr.ch/2024-09-02 09:16:15.graphml\n",
      "Extracting nescherr@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting nescherr@ksr.ch/2024-09-02 09:16:14.graphml\n",
      "Extracting nischnei@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting nischnei@ksr.ch/2024-09-02 09:16:14.graphml\n",
      "Extracting lesieber@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Ignoring lesieber@ksr.ch/ as we need at least two graphs\n",
      "Extracting nivethan@ksr.ch/2024-09-02 07:52:24.graphml\n",
      "Extracting nivethan@ksr.ch/2024-09-02 09:16:15.graphml\n",
      "Extracting heyildiz@ksr.ch/2024-09-02 09:16:16.graphml\n",
      "Ignoring heyildiz@ksr.ch/ as we need at least two graphs\n",
      "Extracting kevichau@ksr.ch/2024-09-02 07:47:57.graphml\n",
      "Extracting kevichau@ksr.ch/2024-09-02 08:19:21.graphml\n",
      "Extracting moeugste@ksr.ch/2024-09-02 07:54:51.graphml\n",
      "Ignoring moeugste@ksr.ch/ as we need at least two graphs\n",
      "Extracting lehasano@ksr.ch/2024-09-02 07:47:58.graphml\n",
      "Ignoring lehasano@ksr.ch/ as we need at least two graphs\n",
      "Extracting samuelle@ksr.ch/2024-09-02 07:47:57.graphml\n",
      "Extracting samuelle@ksr.ch/2024-09-02 08:19:21.graphml\n",
      "Extracting coroesch@ksr.ch/2024-09-02 07:54:52.graphml\n",
      "Extracting coroesch@ksr.ch/2024-09-02 08:19:22.graphml\n",
      "Extracting maschoen@ksr.ch/2024-09-02 07:54:51.graphml\n",
      "Ignoring maschoen@ksr.ch/ as we need at least two graphs\n",
      "Extracting nicoweik@ksr.ch/2024-09-02 07:54:51.graphml\n",
      "Extracting nicoweik@ksr.ch/2024-09-02 08:19:20.graphml\n",
      "Extracting noewirth@ksr.ch/2024-09-02 07:47:57.graphml\n",
      "Extracting noewirth@ksr.ch/2024-09-02 08:19:20.graphml\n",
      "2024-09-02 07:52:24 {'Accelerometer': 0.0, 'Aktor': 0.0, 'Ausrichtung': 0.0, 'Beschleunigung': 0.0, 'Erdanziehung': 0.0, 'Geschwindigkeit': 0.0, 'Gravitation': 0.0, 'Kraft': 0.0, 'Microbit': 0.0, 'Motor': 0.0, 'Roboter': 0.0, 'Schwerelosigkeit': 0.0, 'Sensor': 0.0, 'Vektor': 0.0}\n",
      "2024-09-02 09:16:14 {'Accelerometer': 0.0, 'Aktor': 0.041666666666666664, 'Ausrichtung': 0.0, 'Beschleunigung': 0.8333333333333333, 'Erdanziehung': 0.08333333333333333, 'Geschwindigkeit': 0.0, 'Gravitation': 0.0, 'Kraft': 0.041666666666666664, 'Microbit': 0.16666666666666666, 'Motor': 0.3333333333333333, 'Roboter': 0.0, 'Schwerelosigkeit': 0.0, 'Sensor': 0.0, 'Vektor': 0.0}\n"
     ]
    }
   ],
   "source": [
    "rec2Ma = read_recording('data/Robotics_Acceleration 2Ma.zip')\n",
    "rec2Mf = read_recording('data/Robotics_Acceleration 2Mf.zip')\n",
    "for ts, centrality in rec2Ma['nescherr@ksr.ch/'].items():\n",
    "    print(ts, centrality)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
